# Artificial Intelligence as an Archival Science
## CS7180: Special Topics in AI: Spring 2024

**Class meeting:** Mondays and Thursdays, 11:45am &ndash; 1:25pm

**Instructor:** David Smith (Office hours: TBA; WVH 356 or via zoom)

#### Course Description

A common mode for understanding artificial intelligence systems, from popular fiction to textbooks in computer science, has been the metaphor of an agent that perceives, forms beliefs about, and intervenes in the world. In the past year, some scholars have instead framed large pretrained language and vision models as _cultural technologies_ (Gopnik; Farrell and Shalizi, 2023). Other researchers have pointed out that the builders of large AI models must take on some curatorial tasks in order to be successful and should learn from archival practice (Jo and Gebru, 2020).

In this seminar, we will read and discuss papers addressing large language and vision models as tools to investigate human language, history, and culture; analyzing and auditing corpus creation for model training; and exploring and mitigating biases and gaps in the archives of the past.  Students will take turns presenting and leading discussion of papers along with the relevant background material. All students will write short reviews of the papers we read and work on writing research papers on a topic of their choice.

#### Prerequisites

There are no official prerequisites; however, it is expected that students have some background either in NLP, computer vision, or other machine learning field, or in working computationally with large collections of text and images in the humanities or social sciences.

#### Syllabus

Each week, we will read about two papers on a common theme. The papers could be tied together by methodology&mdash;e.g., model or inference method&mdash;, by subject matter, or by media or archive type.

A list of the first few sets of papers is forthcoming. Further readings will be added by input from seminar participants.  General topics include:

* Computational models as archives
* Archival documentation for models and datasets, &ldquo;collections as data&rdquo;
* Text and Natural Language Processing
  - Literary and narrative archives
  - Documentary archives
* Vision
  - OCR and textual archives: e.g., manuscripts, typewritten records, government archives
  - OCR and visual archives: e.g., text found on images, maps, photographs
  - Image recognition for journalistic and documentary collections
  - Image recognition for art archives
  - Action recognition and audiovisual archives
* Sound
  - Speech recognition: oral history, radio archives
  - Sound classification: music and ambient sound
* Generative Models: Abundance and Loss
  - Missing data
  - Bias, error, and inference
  - Text correction and restoration
  - Image inpainting and video generation
  - Narrative generation
  - Critical fabulation

Readings scheduled so far are as follows:

* January 8: The Sociology of Information. We'll talk about the structure and organization of the course. I'll introduce some of it's themes, drawing one these background readings.
  - Eun So Jo and Timnit Gebru. [Lessons from Archives: Strategies for Collecting Sociocultural Data in Machine Learning.](https://doi.org/10.1145/3351095.3372829) Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, ACM, 2020, pp. 306–16.
  - Part I of: Suzanne Briet. [_What Is Documentation?_](https://roday.pages.iu.edu/what%20is%20documentation.pdf). Translated by Ronald E. Day et al., Scarecrow Press, 2006. [Original text (1951)](http://martinetl.free.fr/suzannebriet/questcequeladocumentation/briet.pdf)
* January 11: Archival and Historical Perspectives on AI
  - Meera Desai, Abigail Jacobs, and Dallas Card. [An Archival Perspective on Pretraining Data](https://openreview.net/forum?id=9xhUufywBX). 2023.
  - An example of documenting an LLM training set: Luca Soldaini. [AI2 Dolma: 3 Trillion Token Open Corpus for Language Model Pretraining](https://blog.allenai.org/dolma-3-trillion-tokens-open-llm-corpus-9a0ff4b8da64). August 18, 2023.
  - States, markets, and AI: Henry Farrell and Cosma Shalizi. [Shoggoths amonst us](https://crookedtimber.org/2023/07/03/shoggoths-amongst-us/). July 3, 2023.
* January 15: MLK Holiday (no class)
* January 18: Cultural Technologies
  - Eunice Yiu, Eliza Kosoy, and Alison Gopnik. [Imitation versus Innovation: What Children Can Do That Large Language and Language-and-Vision Models Cannot (Yet)?](https://arxiv.org/abs/2305.07666). 2023.
  - Chapter 2 of: Albert Lord. [_The Singer of Tales_](https://chs.harvard.edu/read/lord-albert-bates-the-singer-of-tales/). Harvard University Press, 2nd edition 2000, 1st edition 1960.
* January 22: Cultural Evolution
  - Levin Brinkmann et al. [Machine Culture](https://arxiv.org/pdf/2311.11388). _Nature Human Behaviour_, Nov. 2023, pp. 1–14.
